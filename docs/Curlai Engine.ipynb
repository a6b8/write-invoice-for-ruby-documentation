{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5e4b6ab",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f61d094",
   "metadata": {},
   "source": [
    "### sheet_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "138d9df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":sheet_parser"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sheet_parser( obj )\n",
    "  def sheet_parser( json )\n",
    "    columns = []\n",
    "    rows = []\n",
    "\n",
    "    json[\"feed\"][\"entry\"].each do | entry |\n",
    "      columns.push( entry['gs$cell']['col'].to_i )\n",
    "      rows.push( entry['gs$cell']['row'].to_i )\n",
    "    end\n",
    "\n",
    "    items = []\n",
    "    ( 6..rows.max ).each do | row |\n",
    "      item = {\n",
    "        rss: nil,\n",
    "        category: nil,\n",
    "        name: nil,\n",
    "        source: nil\n",
    "      }\n",
    "      [ 1, 4, 5 ].each.with_index do | column, index |\n",
    "        tmp = json[\"feed\"][\"entry\"].find { | entry | \n",
    "          entry['gs$cell']['row'].eql?( row.to_s ) and entry['gs$cell']['col'].eql?( column.to_s )\n",
    "        }\n",
    "        if tmp.nil?\n",
    "          item[ item.keys[ index] ] = ''\n",
    "        else\n",
    "          if column == 1\n",
    "            a = URI.parse( tmp['gs$cell']['$t'] )\n",
    "            b = CGI::parse( URI( tmp['gs$cell']['$t'] ).query )\n",
    "\n",
    "            b.delete(\"category\")\n",
    "\n",
    "            item[ item.keys[ index] ] = \"#{a.scheme}://#{a.host}#{a.path}\"\n",
    "            if b.length > 0\n",
    "              params = URI.encode_www_form( b )\n",
    "              item[ item.keys[ index] ] = \"#{item[ item.keys[ index] ]}?#{params}\"\n",
    "            end\n",
    "\n",
    "          else\n",
    "            item[ item.keys[ index] ] = tmp['gs$cell']['$t']\n",
    "          end\n",
    "        end\n",
    "      end\n",
    "\n",
    "      a = URI.parse( item[:rss] )\n",
    "      case a.host\n",
    "        when 'www.youtube.com'\n",
    "          item[:source] = 'yt'\n",
    "        when 'www.google.com'\n",
    "          item[:source] = 'ga'\n",
    "      end\n",
    "\n",
    "      items.push( item )\n",
    "    end\n",
    "    return items\n",
    "  end\n",
    "\n",
    "  result = []\n",
    " \n",
    "  tabs = obj[:path][:children][:spreadsheet][:files].keys\n",
    "  tabs.each.with_index do | tab, index |\n",
    "    path = obj[:path][:children][:spreadsheet][:files][ tab ][:full]\n",
    "    file = File.read( path )\n",
    "    json = JSON.parse( file )\n",
    "\n",
    "    print \"[#{index}]  #{path}\"\n",
    "    result = result + sheet_parser( json )\n",
    "    puts\n",
    "  end\n",
    "  return result\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204cfb8b",
   "metadata": {},
   "source": [
    "### sheet_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75cc5fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":sheet_clean"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sheet_clean( url, obj, env )\n",
    "  uri = URI( url )\n",
    "  response = Net::HTTP.get( uri )\n",
    "  d = JSON.parse( response )\n",
    "  errors = d['groups'].keys\n",
    "    .map { | a | d['groups'][ a ]['errors'] .map { | a | a['url'] } }\n",
    "    .flatten\n",
    "    .select { | a | URI.parse( a ).host.eql?( 'www.youtube.com' ) }\n",
    "\n",
    "  path = obj[:path][:children][:curlai][:files][:entry][:full]\n",
    "  file = File.read( path )\n",
    "  datas = JSON.parse( file ).with_indifferent_access\n",
    "  d = datas[:data]\n",
    "    .map { | a | a.except( :source ) }\n",
    "    .reject { | a | a[:category].eql?( 'Rap' ) }\n",
    "    .reject { | a | a[:category].eql?( 'Other' ) }\n",
    "    .reject { | a | errors.include?( a[:rss ] ) }\n",
    "  \n",
    "  data = { data: d }\n",
    "  return data\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c777c3d3",
   "metadata": {},
   "source": [
    "### hash_to_rss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b595a119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":hash_to_rss"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def hash_to_rss( title, entries )\n",
    "    result = ''\n",
    "    rss = RSS::Maker.make( 'atom' ) do | maker |\n",
    "      maker.channel.author = ''\n",
    "      maker.channel.updated = Time.now.to_s\n",
    "      maker.channel.about = ''\n",
    "      maker.channel.title = title\n",
    "\n",
    "      entries.each do | entry |\n",
    "        maker.items.new_item do | item |\n",
    "          item.link = entry[:url]\n",
    "          item.title = entry[:title]\n",
    "          item.description = entry[:description]\n",
    "          item.updated = entry[:time][:utc]\n",
    "        end        \n",
    "      end\n",
    "    end\n",
    "\n",
    "    result = rss.to_s.gsub( '<link href=\"', '<link rel=\"alternate\" href=\"' )\n",
    "  return result\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ad22a5",
   "metadata": {},
   "source": [
    "### helper_remove_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2511c9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":helper_remove_html"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def helper_remove_html( html )\n",
    "  result = \"\"\n",
    "  Nokogiri::HTML( CGI.unescapeHTML( html ) ).traverse do | e |\n",
    "    result << e.text if e.text?\n",
    "  end\n",
    "  \n",
    "  result = result\n",
    "    .strip\n",
    "    .split( ' ' )\n",
    "    .map{ | word | word.capitalize }\n",
    "    .join( ' ' )\n",
    "  return result\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e95a6e3",
   "metadata": {},
   "source": [
    "### helper_s3_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6aaadd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":helper_s3_url"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def helper_s3_url( env, obj, type, filename )\n",
    "  url = ''\n",
    "  url << 'https://'\n",
    "  url << env[:AWS_BUCKET_NAME]\n",
    "  url << '.s3.'\n",
    "  url << env[:AWS_REGION]\n",
    "  url << '.amazonaws.com/'\n",
    "  url << env[:AWS_VERSION]\n",
    "  url << obj[:struct][:folders][ type ][:name]\n",
    "  url << filename\n",
    "  return url\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bffe405",
   "metadata": {},
   "source": [
    "### download_rss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cd2678f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":download_rss"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def download_rss( url )\n",
    "  uri = URI( url )\n",
    "  response = Net::HTTP.get( uri )\n",
    "  doc = Nokogiri::XML( response )\n",
    "  return doc\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a34831",
   "metadata": {},
   "source": [
    "### extract_youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "730d7219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":extract_youtube"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_youtube( doc, obj )\n",
    "  def url_html_view( item, obj, channel )\n",
    "    query = {\n",
    "      v: 123,\n",
    "      video_id: nil,\n",
    "      channel_id: nil,\n",
    "      title: nil\n",
    "    }\n",
    "\n",
    "    query[:video_id] = CGI::parse( item[:url].split( '?' )[ 1 ] )['v'][ 0 ]\n",
    "    query[:channel_id] = CGI.parse( channel.split( '?' )[ 1 ] )['channel_id'][ 0 ]\n",
    "    query[:title] = item[:title]\n",
    "\n",
    "    result = ''\n",
    "    result << 'https://'\n",
    "    result << obj[:s3][:bucket_name]\n",
    "    result << '.s3.'\n",
    "    result << obj[:s3][:region]\n",
    "    result << '.amazonaws.com/'\n",
    "    result << obj[:s3][:bucket_sub_folder]\n",
    "    result << obj[:struct][:folders][:viewer][:name]\n",
    "    result << obj[:struct][:folders][:viewer][:files][:yt][:name]\n",
    "    result << '?'\n",
    "    \n",
    "    result << URI.encode_www_form( query )\n",
    "\n",
    "    return result\n",
    "  end\n",
    "  \n",
    "  feed = {\n",
    "      meta: {\n",
    "        title: nil,\n",
    "        url: nil\n",
    "      },\n",
    "      items: []\n",
    "  }\n",
    "  \n",
    "  feed[:meta][:title] = doc.at( 'feed' ).search( 'title' )[ 0 ].text.gsub( '\"',\"'\" )\n",
    "  feed[:meta][:url] = doc.at( 'feed' ).search( 'link' )[ 0 ].attribute( 'href' ).text\n",
    "\n",
    "  entries = doc.at( 'feed' ).search( 'entry' )\n",
    "  entries.each do | entry | \n",
    "    item = {\n",
    "      title: nil,\n",
    "      description: nil,\n",
    "      time: {\n",
    "        stamp: nil,\n",
    "        utc: nil\n",
    "      }\n",
    "    }\n",
    "\n",
    "    item[:title] = ''\n",
    "    item[:title] << \"▫️ \"\n",
    "    item[:title] << feed[:meta][:title].upcase\n",
    "    item[:title] << \" | \"\n",
    "    item[:title] << helper_remove_html( entry.at( 'title' ).text ) \n",
    "\n",
    "    item[:description] = helper_remove_html( entry.xpath( \"//media:description\" ).text )\n",
    "    \n",
    "    threshold = 140\n",
    "    if item[:description].length >= threshold\n",
    "      item[:description] = item[:description][ 0, threshold ]\n",
    "    end\n",
    "\n",
    "    item[:time][:stamp] = Time.parse( entry.at( 'published' ) ).to_i\n",
    "    item[:time][:utc] = entry.at( 'published' ).text\n",
    "\n",
    "    item[:url] = entry.at( 'link' ).attribute( 'href' ).text\n",
    "    item[:url] = url_html_view( item, obj, feed[:meta][:url] )\n",
    "\n",
    "    item[:domain] = URI( item[:url] )\n",
    "      .host\n",
    "      .split( '.' )[ -2, 2 ]\n",
    "      .join( '.' )\n",
    "\n",
    "    feed[:items].push( item )\n",
    "  end\n",
    "\n",
    "  return feed\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba5af22",
   "metadata": {},
   "source": [
    "### analyse_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f19b6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":analyse_single"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analyse_single( url, obj )\n",
    "  doc = download_rss( url )\n",
    "  single = extract_youtube( doc, obj )\n",
    "  return single\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e593a4",
   "metadata": {},
   "source": [
    "### analyse_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78bfc311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":analyse_groups"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analyse_groups( datas, obj )  \n",
    "  keys = datas[:data]\n",
    "    .map { | item | item[:category] }\n",
    "    .to_set\n",
    "    .to_a\n",
    "\n",
    "  groups = {}\n",
    "  keys.each do | key |\n",
    "    groups[ key ] = datas[:data].select { | a | a[:category].eql?( key ) }\n",
    "  end\n",
    "  \n",
    "  result = {}\n",
    "  keys.each.with_index do | key, rindex |\n",
    "    time = {\n",
    "      start: Time.now.to_i,\n",
    "      end: nil,\n",
    "      time: nil\n",
    "    }\n",
    "    \n",
    "    ConsoleHashArray.console( groups, rindex, nil, key, :left )\n",
    "    feeds = []\n",
    "    errors = []\n",
    "    groups[ key ].each.with_index do | item, cindex |\n",
    "      sleep 1\n",
    "      ConsoleHashArray.console( groups, rindex, cindex, key, :right )\n",
    "      url = nil\n",
    "      begin\n",
    "        url = item[:rss]\n",
    "        doc = download_rss( url )\n",
    "        feed = []\n",
    "        case URI.parse( url ).host\n",
    "          when 'www.youtube.com'\n",
    "            feed = extract_youtube( doc, obj )\n",
    "        else\n",
    "          errors.push( {\n",
    "            url: url,\n",
    "            message: 'not parser found'\n",
    "          } )\n",
    "        end\n",
    "        feeds.push( feed )\n",
    "      rescue => e\n",
    "        errors.push( {\n",
    "          url: url,\n",
    "          message: e\n",
    "        } )\n",
    "      end\n",
    "    end\n",
    "    \n",
    "    time[:end] = Time.now.to_i\n",
    "    time[:time] =  Time.now.to_i - time[:start]\n",
    "    \n",
    "    result[ key ] = {\n",
    "      time: time[:time],\n",
    "      feeds: feeds,\n",
    "      errors: errors\n",
    "    }\n",
    "  end\n",
    "  return result\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c8bf4f",
   "metadata": {},
   "source": [
    "### merge_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1b19a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":merge_groups"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def merge_groups( groups_analyse, obj )  \n",
    "  groups_merged = {} \n",
    "  groups_analyse.keys.each.with_index do | key, rindex |\n",
    "    groups_merged[ key ] = {\n",
    "      status: {\n",
    "        message: 'on progress'\n",
    "      },\n",
    "      category: {},\n",
    "      entries: []\n",
    "    }\n",
    "    begin\n",
    "      category = obj[:struct][:categories]\n",
    "        .find { | a | a[:name].eql?( key ) }\n",
    "\n",
    "      groups_merged[ key ][:category] = category\n",
    "      groups_merged[ key ][:entries] = \n",
    "        groups_analyse[ key ][:feeds]\n",
    "          .reject { | a | a.class != Hash }\n",
    "          .map { | a | a[:items] }\n",
    "          .flatten\n",
    "          .sort_by { | a | -a[:time][:stamp] }\n",
    "      \n",
    "      groups_merged[ key ][:status] = {\n",
    "        message: 'success'\n",
    "      }\n",
    "    rescue => e\n",
    "      groups_merged[ key ][:status] = { \n",
    "        message: \"Error: #{e}\"\n",
    "      }\n",
    "    end\n",
    "  end\n",
    "  return groups_merged\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8d619f",
   "metadata": {},
   "source": [
    "### upload_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86329d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":upload_groups"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def upload_groups( merged, obj, env )\n",
    "  time = {\n",
    "    start: Time.now.to_i,\n",
    "    end: nil,\n",
    "    time: nil\n",
    "  }\n",
    "  \n",
    "  result = {\n",
    "    time: nil,\n",
    "    responses: {}\n",
    "  }\n",
    "  \n",
    "  merged.keys.each.with_index do | key, rindex |\n",
    "    begin\n",
    "      ConsoleHashArray.console( merged, rindex, nil, key, :left )\n",
    "      \n",
    "      rss = hash_to_rss( \n",
    "        merged[ key ][:category][:name], \n",
    "        merged[ key ][:entries] \n",
    "      )\n",
    "      \n",
    "      response = upload_single( \n",
    "        rss, \n",
    "        :categories, \n",
    "        merged[ key ][:category][:file], \n",
    "        obj, \n",
    "        env \n",
    "      )  \n",
    "      result[:responses][ key ] = { status: 'success', message: response }\n",
    "      puts \"Success: #{response}\"\n",
    "    rescue => e\n",
    "      result[:responses][ key ] = { status: 'error', message: e }\n",
    "      puts 'error!'\n",
    "    end\n",
    "  end\n",
    "  \n",
    "  time[:end] = Time.now.to_i\n",
    "  time[:time] = time[:end] - time[:start]\n",
    "  \n",
    "  result[:time] = time[:time]\n",
    "  \n",
    "  return result\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45363c9e",
   "metadata": {},
   "source": [
    "### upload_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18dda8aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":upload_single"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def upload_single( body, type, filename, obj, env, content_type = 'application/xml' )\n",
    "  client = Aws::S3::Client.new(\n",
    "    region: env[:AWS_REGION],\n",
    "    access_key_id: env[:AWS_ID],\n",
    "    secret_access_key: env[:AWS_SECRET]\n",
    "  )\n",
    "  \n",
    "  name = ''\n",
    "  name << env[:AWS_VERSION]\n",
    "  name << obj[:struct][:folders][ type ][:name]\n",
    "  name << filename\n",
    "\n",
    "  r = client.put_object(\n",
    "    bucket: obj[:s3][:bucket_name],\n",
    "    content_type: content_type,\n",
    "    key: name,\n",
    "    body: body,\n",
    "    acl: obj[:s3][:access_acl]\n",
    "  )\n",
    "  \n",
    "  url = helper_s3_url( env, obj, type, filename )\n",
    "  return url\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21430007",
   "metadata": {},
   "source": [
    "### upload_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "916cb07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":upload_status"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def upload_status( datas, analyse, merged, uploaded, obj, env ) \n",
    "  messages = {\n",
    "    overview: {\n",
    "      time: {},\n",
    "      all: {},\n",
    "      types: {}\n",
    "    },\n",
    "    groups: {}\n",
    "  }\n",
    "  \n",
    "  analyse.keys.each do | key |\n",
    "    a = {\n",
    "      source: nil,\n",
    "      status: {\n",
    "        analyse: nil,\n",
    "        merge: nil,\n",
    "        upload: nil\n",
    "      },\n",
    "      errors: nil,\n",
    "      time: nil\n",
    "    }\n",
    "\n",
    "    aa = analyse[ key ][:feeds].length\n",
    "    bb = analyse[ key ][:errors].length\n",
    "    cc = aa + bb \n",
    "\n",
    "    a[:status][:analyse] = \"(#{aa}, #{bb}, #{cc})\"\n",
    "    \n",
    "    a[:errors] = analyse[ key ][:errors].map do | item | \n",
    "        search = item[:url] \n",
    "        find = datas[:data]\n",
    "          .find { | a | a[:rss].eql?( search ) }\n",
    "        {\n",
    "          name: find[:name],\n",
    "          url: search\n",
    "        }\n",
    "    end\n",
    "\n",
    "    a[:status][:merge] = merged[ key ][:status][:message]\n",
    "    a[:status][:upload] = uploaded[:responses][ key ][:status]\n",
    "\n",
    "    if uploaded[:responses][ key ][:message].start_with?( 'http' ) \n",
    "      a[:source] = uploaded[:responses][ key ][:message]\n",
    "    end\n",
    "    \n",
    "    a[:time] = analyse[ key ][:time]\n",
    "\n",
    "    messages[:groups][ key ] = a\n",
    "  end\n",
    "  \n",
    "  #puts 'here'\n",
    "  stats = messages[:groups].keys.map do | key |\n",
    "    s = messages[:groups][ key ][:status][:analyse]\n",
    "    s = s  \n",
    "      .gsub( /\\(|\\)|\\s*/, '' )\n",
    "      .split( ',' )\n",
    "      .map { | a | a.to_i }\n",
    "  end\n",
    "  \n",
    "  # messages\n",
    "  messages[:overview][:time][:now] = Time.now\n",
    "  z = analyse.keys\n",
    "    .map { | key | analyse[ key ][:time] }\n",
    "    .sum\n",
    "  \n",
    "  messages[:overview][:time][:analyse] = \n",
    "    Time.at( z ).utc.strftime( \"%Mm %Ss\" )\n",
    "  \n",
    "  zz = uploaded[:time]\n",
    "  messages[:overview][:time][:upload] = \n",
    "    Time.at( zz ).utc.strftime( \"%Mm %Ss\" )\n",
    "  \n",
    "  messages[:overview][:time][:total] = \n",
    "    Time.at( ( zz + z ) ).utc.strftime( \"%Mm %Ss\" )\n",
    "  \n",
    "  r = stats[ 0 ].length.times\n",
    "    .map { | i | stats.inject( 0 ) { | sum, x | sum + x[ i ] } }\n",
    "   # .join( ', ' ) \n",
    "  \n",
    "  messages[:overview][:all] = {}\n",
    "  messages[:overview][:all][:total] = r[ 2 ]\n",
    "  messages[:overview][:all][:error] = r[ 1 ]\n",
    "  messages[:overview][:all][:success] = r[ 0 ]\n",
    "  \n",
    "  #messages[:overview][:status] = \"(#{r})\"\n",
    "  totals = datas[:data]\n",
    "    .map { | a | URI.parse( a[:rss] ).host }\n",
    "    .inject( Hash.new( 0 ) ) { | total, e | total[ e ] += 1; total }\n",
    "  \n",
    "  messages[:overview][:types] = totals.keys.inject( Hash.new( 0 ) ) do | total, e | \n",
    "    total[ e ] = {total: 0, error: 0, success: 0} ; total\n",
    "  end\n",
    "  \n",
    "  totals.keys.each do | key |\n",
    "    messages[:overview][:types][ key ][:total] = totals[ key ]\n",
    "  end\n",
    "  \n",
    "  errors = messages[:groups].keys.map do | key |\n",
    "      messages[:groups][ key ][:errors]\n",
    "        .map { | a | URI.parse( a[:url] ).host }\n",
    "        .inject( Hash.new( 0 ) ) { | total, e | total[ e ] += 1; total }\n",
    "  end\n",
    "  \n",
    "  errors.each do | error |\n",
    "    error.keys.each do | key |\n",
    "      messages[:overview][:types][ key ][ :error ] =\n",
    "        messages[:overview][:types][ key ][ :error ] + error[ key ]\n",
    "    end\n",
    "  end\n",
    "  \n",
    "  messages[:overview][:types].keys.each do | key |\n",
    "    messages[:overview][:types][ key ][:success] =\n",
    "       messages[:overview][:types][ key ][:total] -\n",
    "       messages[:overview][:types][ key ][:error]\n",
    "  end\n",
    "  \n",
    "  str = JSON.pretty_generate( messages )\n",
    "  response = upload_single( \n",
    "    str, \n",
    "    :status, \n",
    "    obj[:struct][:folders][:status][:files][:name], \n",
    "    obj, \n",
    "    env,\n",
    "    'application/json'\n",
    "  )  \n",
    "  return \"URL: #{response} \"\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e80505",
   "metadata": {},
   "source": [
    "### upload_opml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2701c39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":upload_opml"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def upload_opml( obj, env )\n",
    "  opmls = opml_prepare( obj, env )\n",
    "  zip = zip_prepare( opmls )\n",
    "  opmls.keys.each.with_index do | key, index |\n",
    "    value = opmls[ key ]\n",
    "    r = upload_single( value[:body], :opml, value[:meta][:file], obj, env )\n",
    "    puts \"[#{index}] #{r}\"\n",
    "  end\n",
    "  puts\n",
    "  r = upload_single( zip, :opml, 'opmls.zip', obj, env )\n",
    "  puts \"Opml: #{r}\"\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1995b183",
   "metadata": {},
   "source": [
    "### upload_viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b45fc58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":upload_viewer"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def upload_viewer( obj, env )\n",
    "  a = obj[:path][:children][:viewer][:full]\n",
    "  froms = Dir[ a + '*.html' ]\n",
    "    .map { | a | \n",
    "      { \n",
    "        from: a,\n",
    "        filename: File.basename( a ),\n",
    "        body: File.read( a )\n",
    "      } \n",
    "  }\n",
    "\n",
    "  froms.each do | from |\n",
    "    response = upload_single( \n",
    "      from[:body], \n",
    "      :viewer, \n",
    "      from[:filename], \n",
    "      obj, \n",
    "      env, \n",
    "      content_type = '' \n",
    "    )\n",
    "    puts response\n",
    "  end\n",
    "  return true\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3cb8de",
   "metadata": {},
   "source": [
    "### opml_prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fd663a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":opml_prepare"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def opml_prepare( obj, env )\n",
    "  opmls = {}\n",
    "  obj[:struct][:slots].keys.each do | opml |\n",
    "    names = obj[:struct][:categories]\n",
    "      .select { | a | a[:slot].eql?( opml ) }\n",
    "      .map { | a | a[:name] }\n",
    "    opmls[ opml ] = names\n",
    "  end\n",
    "\n",
    "  k = {}\n",
    "  a = opmls.keys.each do | key |\n",
    "    k[ key ] = obj[:struct][:categories].select { | a | a[:slot].eql?( key ) }\n",
    "  end\n",
    "\n",
    "  by_categories = {}\n",
    "  a = opmls.keys.each do | key |\n",
    "    by_categories[ key ] = obj[:struct][:categories]\n",
    "      .select { | aa | aa[:slot].eql?( key ) }\n",
    "  end\n",
    "\n",
    "  result = {}\n",
    "  by_categories.keys.each do | key |\n",
    "    outlines = []\n",
    "    by_categories[ key ].each do | rss |\n",
    "      url = helper_s3_url( env, obj, :categories, rss[:file] )\n",
    "      feed = {\n",
    "        text: rss[:name], \n",
    "        title: rss[:name], \n",
    "        type: \"rss\",\n",
    "        xmlUrl: url,\n",
    "        htmlUrl: url\n",
    "      }\n",
    "      outlines.push( feed )\n",
    "    end\n",
    "\n",
    "    builder = Nokogiri::XML::Builder.new( encoding: 'UTF-8' ) do | xml |\n",
    "      xml.opml( version: \"1.0\" ) do\n",
    "        xml.head { xml.title 'title' }\n",
    "        xml.body { outlines.each { | outline | xml.outline( outline ) } }\n",
    "      end\n",
    "    end\n",
    "    \n",
    "    opml = builder.to_xml\n",
    "    result[ key ] = {\n",
    "      meta: obj[:struct][:slots][ key ],\n",
    "      body: opml\n",
    "    }\n",
    "  end\n",
    "  \n",
    "  return result\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace9ef92",
   "metadata": {},
   "source": [
    "### zip_prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d59005d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":zip_prepare"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def zip_prepare( opmls )\n",
    "  stringio = Zip::OutputStream.write_buffer do |zio|\n",
    "    opmls.keys.each do | key |\n",
    "      zio.put_next_entry( opmls[ key ][:meta][:file] )\n",
    "      zio.write( opmls[ key ][:body] )\n",
    "    end\n",
    "  end\n",
    "  body = stringio.string\n",
    "  return body\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b1c313",
   "metadata": {},
   "source": [
    "## Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c100a5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "require 'open-uri'\n",
    "require 'local_path_builder'\n",
    "require 'net/http'\n",
    "require \"active_support/core_ext/hash/indifferent_access\"\n",
    "require 'json'\n",
    "require 'active_support/core_ext/hash'\n",
    "require 'nokogiri'\n",
    "require 'rss'\n",
    "require 'aws-sdk-s3'\n",
    "require 'faker'\n",
    "require 'console_hash_array'\n",
    "require 'zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ffd2a80",
   "metadata": {},
   "outputs": [
    {
     "ename": "Errno::ENOENT",
     "evalue": "No such file or directory @ rb_sysopen - ./.env",
     "output_type": "error",
     "traceback": [
      "\u001b[31mErrno::ENOENT\u001b[0m: No such file or directory @ rb_sysopen - ./.env",
      "(irb):1:in `read'",
      "(irb):1:in `<main>'"
     ]
    }
   ],
   "source": [
    "env = File\n",
    "  .read( './.env' )\n",
    "  .split( \"\\n\" )\n",
    "  .map { | n | n.split( /=(.+)/ ) }\n",
    "  .to_h\n",
    "  .with_indifferent_access\n",
    "\n",
    "hash = {\n",
    "  spreadsheet: {\n",
    "    id: '12vzGqg_KaXDvjYkFQAsLqQ1aEsUlZbaOOPiadYREpZE'\n",
    "  },\n",
    "  path: {\n",
    "    root: './',\n",
    "    name: 'files',\n",
    "    children: {\n",
    "      spreadsheet: {\n",
    "        name: '0-spreadsheets',\n",
    "        files: {\n",
    "          tab1: {\n",
    "            name: '1-youtube.json'\n",
    "          },\n",
    "          tab2: {\n",
    "            name: '2-alerts.json'\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      curlai: {\n",
    "        name: '1-curlai',\n",
    "        files: {\n",
    "          short: { name: '2-short.json' },\n",
    "          entry: { name: '1-entry.json' },\n",
    "          meta: { name: '0-meta.json' }\n",
    "        }\n",
    "      },\n",
    "      viewer: {\n",
    "        name: '2-viewer'\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  struct: {\n",
    "    folders: {\n",
    "      status: {\n",
    "        name: 'status/',\n",
    "        files: {\n",
    "          name: 'status.json'\n",
    "        }\n",
    "      },\n",
    "      opml: {\n",
    "        name: 'opml/'\n",
    "      },\n",
    "      categories: {\n",
    "        name: 'categories/',\n",
    "      },\n",
    "      viewer: {\n",
    "        name: 'viewer/',\n",
    "        files: {\n",
    "          yt: {\n",
    "            name: 'yt.html'\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    },\n",
    "    opml: {},\n",
    "    slots: {\n",
    "      morning: { name: 'Morning', file: 'morning.opml' },\n",
    "      evening: { name: 'Evening', file: 'evening.opml' },\n",
    "      news: { name: 'News', file: 'news.opml' },\n",
    "      other: { name: 'Other', file: 'other.opml' }\n",
    "    },\n",
    "    categories: [\n",
    "      { name: 'Music', file: 'music.xml', slot: :evening },\n",
    "      { name: 'Art', file: 'art.xml', slot: :evening },\n",
    "      { name: 'Sport', file: 'sport.xml', slot: :evening },\n",
    "      { name: 'Programming', file: 'programming.xml', slot: :evening },\n",
    "      { name: 'Universe', file: 'universe.xml', slot: :evening },\n",
    "      { name: 'Lifestyle', file: 'lifestyle.xml', slot: :evening },\n",
    "      { name: 'Philosophie', file: 'philosophie.xml', slot: :evening },\n",
    "      { name: 'Talks Tech', file: 'talks-tech.xml', slot: :morning },\n",
    "      { name: 'Startup', file: 'startup.xml', slot: :morning },\n",
    "      { name: 'Hype Technologies', file: 'hype-technologies.xml', slot: :morning },\n",
    "      { name: 'Artificial Intelligence', file: 'artificial-intelligence.xml', slot: :morning },\n",
    "      { name: 'Research', file: 'research.xml', slot: :morning },\n",
    "      { name: 'Development', file: 'development.xml', slot: :morning },\n",
    "      { name: 'Talks Business', file: 'talks-business.xml', slot: :morning },\n",
    "      { name: 'Hypecycle (A-D)', file: 'hypecycle-(a-d).xml', slot: :news },\n",
    "      { name: 'Hypecycle (E-L)', file: 'hypecycle-(e-l).xml', slot: :news },\n",
    "      { name: 'Hypecycle (M-R)', file: 'hypecycle-(m-r).xml', slot: :news },\n",
    "      { name: 'Hypecycle (S-Z)', file: 'hypecycle-(s-z).xml', slot: :news },\n",
    "      { name: 'Persons', file: 'persons.xml', slot: :news },\n",
    "      { name: 'Programming Topics', file: 'programming-topics.xml', slot: :news },\n",
    "      { name: 'Politics', file: 'politics.xml', slot: :news },\n",
    "      { name: 'Other', file: 'other.xml', slot: :other },\n",
    "      { name: 'Rap', file: 'rap.xml', slot: :news }\n",
    "    ]\n",
    "  },\n",
    "  s3: {\n",
    "    bucket_name: nil,\n",
    "    bucket_sub_folder: nil,\n",
    "    region: nil,\n",
    "    access_acl: 'public-read',\n",
    "    filename_with_subfolder: nil,\n",
    "  }\n",
    "}\n",
    "\n",
    "hash[:s3][:bucket_name] = env[:AWS_BUCKET_NAME]\n",
    "hash[:s3][:bucket_sub_folder] = env[:AWS_VERSION]\n",
    "hash[:s3][:region] = env[:AWS_REGION]\n",
    "\n",
    "# hash[:struct][:meta][:opml] = \"#{hash[:struct][:meta][:s3]}opml.zip\"\n",
    "\n",
    "# hash[:struct][:categories].each.with_index do | a, index |\n",
    "#  hash[:struct][:categories][ index ][:path] = \n",
    "#  \"#{hash[:struct][:meta][:s3]}#{hash[:struct][:categories][ index ][:file]}\"\n",
    "# end\n",
    "\n",
    "LocalPathBuilder.generate( hash[:path], :both )\n",
    "puts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1715cda",
   "metadata": {},
   "source": [
    "### Upload opml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd3a7f62",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoMethodError",
     "evalue": "undefined method `[]' for nil:NilClass",
     "output_type": "error",
     "traceback": [
      "\u001b[31mNoMethodError\u001b[0m: undefined method `[]' for nil:NilClass",
      "(irb):2:in `opml_prepare'",
      "(irb):1:in `upload_opml'",
      "(irb):in `<main>'"
     ]
    }
   ],
   "source": [
    "upload_opml( hash, env )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55496321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n"
     ]
    }
   ],
   "source": [
    "puts 'A'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a569da",
   "metadata": {},
   "source": [
    "### Upload Viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0858511d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoMethodError",
     "evalue": "undefined method `[]' for nil:NilClass",
     "output_type": "error",
     "traceback": [
      "\u001b[31mNoMethodError\u001b[0m: undefined method `[]' for nil:NilClass",
      "(irb):1:in `upload_viewer'",
      "(irb):in `<main>'"
     ]
    }
   ],
   "source": [
    "upload_viewer( hash, env )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698f7596",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4069843",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoMethodError",
     "evalue": "undefined method `[]' for nil:NilClass",
     "output_type": "error",
     "traceback": [
      "\u001b[31mNoMethodError\u001b[0m: undefined method `[]' for nil:NilClass",
      "(irb):in `<main>'"
     ]
    }
   ],
   "source": [
    "path = hash[:path][:children][:curlai][:files][:meta][:full]\n",
    "File.open( path, \"w\" ) { | f | f.write( JSON.pretty_generate( hash[:struct] ) ) }\n",
    "\n",
    "items = { data: spreadsheet_parser( hash ) } \n",
    "path = hash[:path][:children][:curlai][:files][:entry][:full]\n",
    "File.open( path, \"w\" ) { | f | f.write( JSON.pretty_generate( items ) ) }\n",
    "puts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c46a1d",
   "metadata": {},
   "source": [
    "### Data Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "487cf5e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoMethodError",
     "evalue": "undefined method `[]' for nil:NilClass",
     "output_type": "error",
     "traceback": [
      "\u001b[31mNoMethodError\u001b[0m: undefined method `[]' for nil:NilClass",
      "(irb):in `<main>'"
     ]
    }
   ],
   "source": [
    "url = helper_s3_url( env, hash, :status, hash[:struct][:folders][:status][:files][:name] )\n",
    "data = sheet_clean( url, hash, env )\n",
    "path = hash[:path][:children][:curlai][:files][:short][:full]\n",
    "File.open( path, \"w\" ) { | f | f.write( JSON.pretty_generate( data ) ) }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6e3d8f",
   "metadata": {},
   "source": [
    "### Analyse Single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c349ebe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoMethodError",
     "evalue": "undefined method `[]' for nil:NilClass",
     "output_type": "error",
     "traceback": [
      "\u001b[31mNoMethodError\u001b[0m: undefined method `[]' for nil:NilClass",
      "(irb):in `<main>'"
     ]
    }
   ],
   "source": [
    "path = hash[:path][:children][:curlai][:files][:entry][:full]\n",
    "file = File.read( path )\n",
    "datas = JSON.parse( file ).with_indifferent_access\n",
    "url = datas[:data][ 0 ][:rss]\n",
    "single = analyse_single( url, hash )\n",
    "puts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4e269f",
   "metadata": {},
   "source": [
    "### Analyse Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "795d7dd1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoMethodError",
     "evalue": "undefined method `[]' for nil:NilClass",
     "output_type": "error",
     "traceback": [
      "\u001b[31mNoMethodError\u001b[0m: undefined method `[]' for nil:NilClass",
      "(irb):in `<main>'"
     ]
    }
   ],
   "source": [
    "path = hash[:path][:children][:curlai][:files][:short][:full]\n",
    "file = File.read( path )\n",
    "datas = JSON.parse( file ).with_indifferent_access\n",
    "groups_analyse = analyse_groups( datas, hash )\n",
    "groups_merged = merge_groups( groups_analyse, hash )\n",
    "puts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddaa95b",
   "metadata": {},
   "source": [
    "### Upload Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "784c96b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoMethodError",
     "evalue": "undefined method `keys' for nil:NilClass",
     "output_type": "error",
     "traceback": [
      "\u001b[31mNoMethodError\u001b[0m: undefined method `keys' for nil:NilClass",
      "(irb):12:in `upload_groups'",
      "(irb):in `<main>'"
     ]
    }
   ],
   "source": [
    "groups_upload = upload_groups( groups_merged, hash, env )\n",
    "puts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938f04b0",
   "metadata": {},
   "source": [
    "### Upload Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44b15341",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoMethodError",
     "evalue": "undefined method `keys' for nil:NilClass",
     "output_type": "error",
     "traceback": [
      "\u001b[31mNoMethodError\u001b[0m: undefined method `keys' for nil:NilClass",
      "(irb):10:in `upload_status'",
      "(irb):in `<main>'"
     ]
    }
   ],
   "source": [
    "upload_status( \n",
    "  datas,\n",
    "  groups_analyse,\n",
    "  groups_merged,\n",
    "  groups_upload,\n",
    "  hash, \n",
    "  env\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c31d34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08212679",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoMethodError",
     "evalue": "undefined method `[]' for nil:NilClass",
     "output_type": "error",
     "traceback": [
      "\u001b[31mNoMethodError\u001b[0m: undefined method `[]' for nil:NilClass",
      "(irb):in `<main>'"
     ]
    }
   ],
   "source": [
    "groups_merged['Art'][:entries][ 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddad8213",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ruby 3.0.0",
   "language": "ruby",
   "name": "ruby"
  },
  "language_info": {
   "file_extension": ".rb",
   "mimetype": "application/x-ruby",
   "name": "ruby",
   "version": "3.0.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "264.390625px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
